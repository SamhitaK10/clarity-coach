<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Voice Coach - Realtime AI</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(180deg, #F19D4F 0%, #FF7A25 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: rgba(58, 46, 40, 0.9);
            border-radius: 16px;
            padding: 40px;
            max-width: 600px;
            width: 100%;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            color: #FAF5F0;
        }

        h1 {
            text-align: center;
            margin-bottom: 10px;
            font-size: 28px;
            color: #FF7A25;
        }

        .subtitle {
            text-align: center;
            font-size: 14px;
            opacity: 0.8;
            margin-bottom: 30px;
        }

        .status-box {
            background: rgba(250, 245, 240, 0.1);
            border: 2px solid #FF6B5A;
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 30px;
            text-align: center;
        }

        .status-indicator {
            display: inline-flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 10px;
        }

        .status-dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #888;
            animation: none;
        }

        .status-dot.connecting {
            background: #FFB700;
            animation: pulse 1.5s ease-in-out infinite;
        }

        .status-dot.listening {
            background: #4CAF50;
            animation: pulse 1s ease-in-out infinite;
        }

        .status-dot.speaking {
            background: #2196F3;
            animation: pulse 0.8s ease-in-out infinite;
        }

        .status-dot.error {
            background: #F44336;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .status-text {
            font-size: 16px;
            font-weight: 600;
            color: #FAF5F0;
        }

        .button-group {
            display: flex;
            gap: 15px;
            margin-bottom: 20px;
        }

        button {
            flex: 1;
            padding: 16px 24px;
            font-size: 16px;
            font-weight: 600;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .btn-primary {
            background: #FF6B5A;
            color: white;
            box-shadow: 0 4px 15px rgba(255, 107, 90, 0.4);
        }

        .btn-primary:hover:not(:disabled) {
            background: #E65A49;
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(255, 107, 90, 0.6);
        }

        .btn-primary:disabled {
            background: #888;
            cursor: not-allowed;
            opacity: 0.5;
        }

        .btn-secondary {
            background: #666;
            color: white;
        }

        .btn-secondary:hover:not(:disabled) {
            background: #555;
            transform: translateY(-2px);
        }

        .btn-secondary:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .transcript-section {
            background: rgba(58, 46, 40, 0.5);
            border-radius: 12px;
            padding: 20px;
            margin-top: 20px;
        }

        .transcript-label {
            font-size: 12px;
            text-transform: uppercase;
            color: #FF7A25;
            margin-bottom: 10px;
            font-weight: 600;
            letter-spacing: 1px;
        }

        #transcript {
            min-height: 80px;
            font-size: 14px;
            line-height: 1.6;
            color: #FAF5F0;
            word-wrap: break-word;
            max-height: 150px;
            overflow-y: auto;
        }

        .error-message {
            background: rgba(244, 67, 54, 0.2);
            border-left: 4px solid #F44336;
            padding: 12px;
            margin-top: 15px;
            border-radius: 4px;
            color: #FFB3B3;
            font-size: 14px;
            display: none;
        }

        .error-message.show {
            display: block;
        }

        .info-text {
            font-size: 12px;
            color: #AAA;
            text-align: center;
            margin-top: 20px;
            line-height: 1.6;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Live Voice Coach</h1>
        <div class="subtitle">Powered by OpenAI Realtime API</div>

        <!-- Status Display -->
        <div class="status-box">
            <div class="status-indicator">
                <div class="status-dot" id="statusDot"></div>
                <div class="status-text" id="statusText">Ready</div>
            </div>
            <div style="font-size: 12px; opacity: 0.7; margin-top: 8px;">
                <span id="connectionInfo">Not connected</span>
            </div>
        </div>

        <!-- Control Buttons -->
        <div class="button-group">
            <button class="btn-primary" id="startBtn" onclick="startCoaching()">
                Talk to Coach
            </button>
            <button class="btn-secondary" id="stopBtn" onclick="stopCoaching()" disabled>
                Stop Coaching
            </button>
        </div>

        <!-- Error Message -->
        <div class="error-message" id="errorMessage"></div>

        <!-- Transcript Section -->
        <div class="transcript-section">
            <div class="transcript-label">Conversation</div>
            <div id="transcript">Waiting for input...</div>
        </div>

        <!-- Info Text -->
        <div class="info-text">
            üí° Allow microphone access when prompted<br>
            üéµ AI responses play automatically<br>
            ‚èπÔ∏è Click "Stop Coaching" to disconnect
        </div>
    </div>

    <!-- Hidden audio element for AI responses -->
    <audio id="aiAudio" autoplay></audio>

    <script>
        // ============================================================================
        // STATE
        // ============================================================================
        let state = {
            peerConnection: null,
            mediaStream: null,
            isConnected: false,
            audioElement: null,
        };

        // ============================================================================
        // DOM ELEMENTS
        // ============================================================================
        const statusDot = document.getElementById('statusDot');
        const statusText = document.getElementById('statusText');
        const connectionInfo = document.getElementById('connectionInfo');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const transcript = document.getElementById('transcript');
        const errorMessage = document.getElementById('errorMessage');
        const aiAudio = document.getElementById('aiAudio');

        // ============================================================================
        // UTILITY FUNCTIONS
        // ============================================================================

        /**
         * Update the UI status indicator
         */
        function updateStatus(status, message) {
            statusDot.className = 'status-dot';
            statusText.textContent = message;

            switch (status) {
                case 'connecting':
                    statusDot.classList.add('connecting');
                    break;
                case 'listening':
                    statusDot.classList.add('listening');
                    break;
                case 'speaking':
                    statusDot.classList.add('speaking');
                    break;
                case 'error':
                    statusDot.classList.add('error');
                    break;
            }
        }

        function showError(message) {
            console.error('‚ùå', message);
            errorMessage.textContent = message;
            errorMessage.classList.add('show');
            updateStatus('error', 'Error');
        }

        function clearError() {
            errorMessage.classList.remove('show');
            errorMessage.textContent = '';
        }

        // ============================================================================
        // BACKEND INTEGRATION
        // ============================================================================

        /**
         * Get ephemeral token from backend
         */
        async function getSessionToken() {
            try {
                console.log('üì° Requesting ephemeral token from backend...');
                const response = await fetch('/api/session', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                });

                if (!response.ok) {
                    throw new Error(`Backend error: ${response.status}`);
                }

                const data = await response.json();
                console.log('‚úÖ Ephemeral token received');
                console.log('   Token type:', typeof data.client_secret.value);
                console.log('   Token length:', data.client_secret.value.length);
                
                return data.client_secret.value;
            } catch (err) {
                throw new Error('Failed to get session token: ' + err.message);
            }
        }

        // ============================================================================
        // REALTIME VOICE CONTROL
        // ============================================================================

        /**
         * Start realtime voice coaching using WebRTC
         */
        async function startCoaching() {
            try {
                console.log('\nüéØ Starting realtime voice coaching...');
                clearError();
                updateStatus('connecting', 'Connecting...');
                startBtn.disabled = true;
                stopBtn.disabled = false;
                transcript.innerHTML = 'Initializing...';

                // Step 1: Request microphone access
                console.log('üé§ Step 1: Requesting microphone access...');
                connectionInfo.textContent = 'Requesting microphone...';
                
                try {
                    state.mediaStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: true 
                    });
                    console.log('‚úÖ Microphone access granted');
                } catch (err) {
                    showError('Microphone access denied. Please allow access to continue.');
                    startBtn.disabled = false;
                    stopBtn.disabled = true;
                    return;
                }

                // Step 2: Get ephemeral token from backend
                console.log('üîê Step 2: Getting ephemeral token...');
                connectionInfo.textContent = 'Getting auth token...';
                const token = await getSessionToken();

                // Step 3: Connect to OpenAI Realtime
                console.log('üîó Step 3: Connecting to OpenAI Realtime...');
                connectionInfo.textContent = 'Connecting to realtime API...';
                await connectToRealtime(token);

                console.log('‚úÖ Realtime voice coaching started\n');
                connectionInfo.textContent = 'Connected ‚úì';
                updateStatus('listening', 'Listening...');
                transcript.innerHTML = '';

            } catch (err) {
                console.error('‚ùå Coaching error:', err.message);
                showError(err.message);
                stopCoaching();
            }
        }

        /**
         * Connect to OpenAI Realtime via WebRTC
         */
        async function connectToRealtime(token) {
            return new Promise((resolve, reject) => {
                try {
                    console.log('üîó Creating WebRTC peer connection...');
                    
                    // Create peer connection
                    state.peerConnection = new RTCPeerConnection();
                    
                    // Handle incoming audio
                    state.peerConnection.ontrack = (event) => {
                        console.log('üéµ Receiving audio track from OpenAI');
                        if (aiAudio.srcObject !== event.streams[0]) {
                            aiAudio.srcObject = event.streams[0];
                        }
                    };

                    // Add local audio tracks
                    console.log('üé§ Adding local audio tracks...');
                    state.mediaStream.getTracks().forEach(track => {
                        state.peerConnection.addTrack(track, state.mediaStream);
                    });

                    // Handle connection state changes
                    state.peerConnection.onconnectionstatechange = () => {
                        console.log('üîå WebRTC connection state:', state.peerConnection.connectionState);
                        switch (state.peerConnection.connectionState) {
                            case 'connected':
                                console.log('‚úÖ WebRTC connected');
                                state.isConnected = true;
                                updateStatus('listening', 'Listening...');
                                break;
                            case 'disconnected':
                            case 'failed':
                            case 'closed':
                                console.log('‚ùå WebRTC disconnected');
                                state.isConnected = false;
                                stopCoaching();
                                break;
                        }
                    };

                    // Create offer
                    console.log('üìù Creating WebRTC offer...');
                    state.peerConnection.createOffer().then(offer => {
                        console.log('‚úÖ Offer created, setting local description...');
                        return state.peerConnection.setLocalDescription(offer);
                    }).then(() => {
                        // Send offer to OpenAI
                        console.log('üì§ Sending offer to OpenAI...');
                        console.log('   URL: https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview');
                        console.log('   Auth: Bearer ' + token.substring(0, 10) + '...***');
                        
                        return fetch('https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview', {
                            method: 'POST',
                            headers: {
                                'Authorization': `Bearer ${token}`,
                                'Content-Type': 'application/sdp'
                            },
                            body: state.peerConnection.localDescription.sdp
                        });
                    }).then(response => {
                        if (!response.ok) {
                            throw new Error(`OpenAI error: ${response.status}`);
                        }
                        console.log('üì• Received answer from OpenAI');
                        return response.text();
                    }).then(answerSDP => {
                        console.log('‚öôÔ∏è  Setting remote description...');
                        return state.peerConnection.setRemoteDescription({
                            type: 'answer',
                            sdp: answerSDP
                        });
                    }).then(() => {
                        console.log('‚úÖ Realtime connection established');
                        resolve(true);
                    }).catch(err => {
                        console.error('‚ùå WebRTC setup error:', err.message);
                        reject(err);
                    });

                } catch (err) {
                    console.error('‚ùå Connection error:', err);
                    reject(err);
                }
            });
        }

        /**
         * Stop the coaching session
         */
        function stopCoaching() {
            console.log('‚èπÔ∏è Stopping coaching session...');

            // Close peer connection
            if (state.peerConnection) {
                state.peerConnection.close();
                state.peerConnection = null;
            }

            // Stop media stream
            if (state.mediaStream) {
                state.mediaStream.getTracks().forEach(track => track.stop());
                state.mediaStream = null;
            }

            // Stop audio playback
            if (aiAudio.srcObject) {
                aiAudio.srcObject.getTracks().forEach(track => track.stop());
                aiAudio.srcObject = null;
            }

            state.isConnected = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;
            updateStatus('ready', 'Ready');
            connectionInfo.textContent = 'Not connected';
            transcript.innerHTML = 'Session ended.';

            console.log('‚úÖ Session stopped\n');
        }
    </script>
</body>
</html>
